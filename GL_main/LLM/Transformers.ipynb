{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Using Pre-Trained Model"
      ],
      "metadata": {
        "id": "2VsGsWjjY04F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q transformers sentencepiece nltk rouge-score\n",
        "\n",
        "from transformers import MarianMTModel, MarianTokenizer\n",
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "from rouge_score import rouge_scorer\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')\n",
        "\n",
        "english_sentences = [\n",
        "    \"hello\", \"how are you\", \"i am fine\", \"what is your name\", \"nice to meet you\",\n",
        "    \"i love machine learning\", \"do you like pizza\", \"good morning\", \"thank you\", \"see you later\"\n",
        "]\n",
        "french_sentences = [\n",
        "    \"bonjour\", \"comment ça va\", \"je vais bien\", \"quel est ton nom\", \"ravi de vous rencontrer\",\n",
        "    \"j'aime l'apprentissage automatique\", \"aimes-tu la pizza\", \"bonjour\", \"merci\", \"à plus tard\"\n",
        "]\n",
        "\n",
        "model_name = \"Helsinki-NLP/opus-mt-en-fr\"\n",
        "tokenizer = MarianTokenizer.from_pretrained(model_name)\n",
        "model = MarianMTModel.from_pretrained(model_name)\n",
        "\n",
        "results = []\n",
        "for i, src in enumerate(english_sentences):\n",
        "    inputs = tokenizer(src, return_tensors=\"pt\", padding=True)\n",
        "    translated = model.generate(**inputs)\n",
        "    tgt = tokenizer.decode(translated[0], skip_special_tokens=True)\n",
        "\n",
        "    reference = [nltk.word_tokenize(french_sentences[i])]\n",
        "    prediction = nltk.word_tokenize(tgt)\n",
        "    bleu = sentence_bleu(reference, prediction)\n",
        "    rouge = rouge_scorer.RougeScorer(['rouge1', 'rouge2'], use_stemmer=True).score(\n",
        "        ' '.join(reference[0]), ' '.join(prediction))\n",
        "\n",
        "    results.append({\n",
        "        \"English\": src,\n",
        "        \"French (Reference)\": french_sentences[i],\n",
        "        \"Predicted French\": tgt,\n",
        "        \"BLEU\": round(bleu, 4),\n",
        "        \"ROUGE-1\": round(rouge['rouge1'].fmeasure, 4),\n",
        "        \"ROUGE-2\": round(rouge['rouge2'].fmeasure, 4)\n",
        "    })\n",
        "\n",
        "import pandas as pd\n",
        "pd.DataFrame(results)"
      ],
      "metadata": {
        "id": "hCrVIFyQYz_V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Using model from scratch with small datset"
      ],
      "metadata": {
        "id": "6XAE7b7dY4RG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c1QsDTv4LJEq"
      },
      "outputs": [],
      "source": [
        "# Step 1: Install and import libraries\n",
        "!pip install -q datasets nltk rouge-score\n",
        "\n",
        "from datasets import load_dataset\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import nltk\n",
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "from rouge_score import rouge_scorer\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Step 2: Prepare a small dataset (English-French)\n",
        "english_sentences = [\n",
        "    \"hello\", \"how are you\", \"i am fine\", \"what is your name\", \"nice to meet you\",\n",
        "    \"i love machine learning\", \"do you like pizza\", \"good morning\", \"thank you\", \"see you later\"\n",
        "]\n",
        "\n",
        "french_sentences = [\n",
        "    \"bonjour\", \"comment ça va\", \"je vais bien\", \"quel est ton nom\", \"ravi de vous rencontrer\",\n",
        "    \"j'aime l'apprentissage automatique\", \"aimes-tu la pizza\", \"bonjour\", \"merci\", \"à plus tard\"\n",
        "]\n",
        "\n",
        "# Step 3: Tokenization\n",
        "def tokenize(sentences, num_words=10000):\n",
        "    tokenizer = Tokenizer(num_words=num_words, oov_token='<OOV>')\n",
        "    tokenizer.fit_on_texts(sentences)\n",
        "    tensor = tokenizer.texts_to_sequences(sentences)\n",
        "    return tokenizer, pad_sequences(tensor, padding='post')\n",
        "\n",
        "en_tokenizer, en_tensor = tokenize(english_sentences)\n",
        "fr_tokenizer, fr_tensor = tokenize(french_sentences)\n",
        "input_vocab_size = len(en_tokenizer.word_index) + 1\n",
        "target_vocab_size = len(fr_tokenizer.word_index) + 1\n",
        "\n",
        "# Step 4: Define transformer model\n",
        "class Transformer(tf.keras.Model):\n",
        "    def __init__(self, input_vocab, target_vocab, d_model, num_heads, dff, pe_input, pe_target):\n",
        "        super().__init__()\n",
        "        self.encoder_embedding = tf.keras.layers.Embedding(input_vocab, d_model)\n",
        "        self.decoder_embedding = tf.keras.layers.Embedding(target_vocab, d_model)\n",
        "        self.pos_encoding_input = self.positional_encoding(pe_input, d_model)\n",
        "        self.pos_encoding_target = self.positional_encoding(pe_target, d_model)\n",
        "\n",
        "        self.enc_layer = tf.keras.layers.MultiHeadAttention(num_heads=num_heads, key_dim=d_model)\n",
        "        self.dec_layer = tf.keras.layers.MultiHeadAttention(num_heads=num_heads, key_dim=d_model)\n",
        "        self.dense_proj = tf.keras.Sequential([\n",
        "            tf.keras.layers.Dense(dff, activation='relu'),\n",
        "            tf.keras.layers.Dense(d_model)\n",
        "        ])\n",
        "        self.final_dense = tf.keras.layers.Dense(target_vocab)\n",
        "\n",
        "    def positional_encoding(self, max_len, dm):\n",
        "        pos = np.arange(max_len)[:, np.newaxis]\n",
        "        i = np.arange(dm)[np.newaxis, :]\n",
        "        angle_rates = 1 / np.power(10000, (2 * (i//2)) / np.float32(dm))\n",
        "        angle_rads = pos * angle_rates\n",
        "        angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
        "        angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
        "        return tf.cast(angle_rads, dtype=tf.float32)\n",
        "\n",
        "    def call(self, inputs, training=False):\n",
        "        inp, tar = inputs\n",
        "        enc = self.encoder_embedding(inp) + self.pos_encoding_input[:tf.shape(inp)[1]]\n",
        "        dec = self.decoder_embedding(tar) + self.pos_encoding_target[:tf.shape(tar)[1]]\n",
        "        enc_output = self.enc_layer(enc, enc)\n",
        "        dec_output = self.dec_layer(dec, enc_output)\n",
        "        final = self.dense_proj(dec_output)\n",
        "        return self.final_dense(final)\n",
        "\n",
        "# Step 5: Compile and train\n",
        "model = Transformer(input_vocab=input_vocab_size, target_vocab=target_vocab_size,\n",
        "                    d_model=64, num_heads=4, dff=128, pe_input=en_tensor.shape[1], pe_target=fr_tensor.shape[1])\n",
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "model.fit([en_tensor, fr_tensor[:, :-1]], fr_tensor[:, 1:], epochs=20, batch_size=32)\n",
        "\n",
        "# Step 6: Translation function\n",
        "def translate(sentence):\n",
        "    seq = en_tokenizer.texts_to_sequences([sentence])\n",
        "    padded = pad_sequences(seq, maxlen=en_tensor.shape[1], padding='post')\n",
        "    decoder_input = np.zeros((1, fr_tensor.shape[1]), dtype=np.int32)\n",
        "    decoder_input[0][0] = fr_tokenizer.word_index.get('<sos>', 1)\n",
        "\n",
        "    for i in range(1, fr_tensor.shape[1]):\n",
        "        output = model([padded, decoder_input[:, :-1]], training=False)\n",
        "        pred_id = tf.argmax(output[0, i-1]).numpy()\n",
        "        decoder_input[0][i] = pred_id\n",
        "        if pred_id == fr_tokenizer.word_index.get('<eos>'):\n",
        "            break\n",
        "\n",
        "    return ' '.join([fr_tokenizer.index_word.get(idx, '') for idx in decoder_input[0] if idx != 0])\n",
        "\n",
        "# Step 7: Evaluation\n",
        "results = []\n",
        "for i in range(10):\n",
        "    ref = [nltk.word_tokenize(french_sentences[i].replace('<sos>', '').replace('<eos>', '').strip())]\n",
        "    pred = nltk.word_tokenize(translate(english_sentences[i]))\n",
        "    bleu = sentence_bleu(ref, pred)\n",
        "    rouge = rouge_scorer.RougeScorer(['rouge1', 'rouge2'], use_stemmer=True).score(' '.join(ref[0]), ' '.join(pred))\n",
        "    results.append((english_sentences[i], french_sentences[i].replace('<sos>', '').replace('<eos>', '').strip(), ' '.join(pred), bleu, rouge['rouge1'].fmeasure, rouge['rouge2'].fmeasure))\n",
        "\n",
        "import pandas as pd\n",
        "pd.DataFrame(results, columns=[\"English\", \"French (Reference)\", \"Predicted French\", \"BLEU\", \"ROUGE-1\", \"ROUGE-2\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Using model from scratch with big datset"
      ],
      "metadata": {
        "id": "qPoPstQGY-K-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Install and import libraries\n",
        "!pip install -q datasets nltk rouge-score\n",
        "\n",
        "from datasets import load_dataset\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import nltk\n",
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "from rouge_score import rouge_scorer\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Step 2: Load a real translation dataset (English-French)\n",
        "data = load_dataset(\"opus_books\", \"en-fr\", split='train[:10000]')\n",
        "english_sentences = [f\"{x['translation']['en']}\" for x in data]\n",
        "french_sentences = [f\"<sos> {x['translation']['fr']} <eos>\" for x in data]\n",
        "\n",
        "# Step 3: Tokenization\n",
        "def tokenize(sentences, num_words=10000):\n",
        "    tokenizer = Tokenizer(num_words=num_words, oov_token='<OOV>')\n",
        "    tokenizer.fit_on_texts(sentences)\n",
        "    tensor = tokenizer.texts_to_sequences(sentences)\n",
        "    return tokenizer, pad_sequences(tensor, padding='post')\n",
        "\n",
        "en_tokenizer, en_tensor = tokenize(english_sentences)\n",
        "fr_tokenizer, fr_tensor = tokenize(french_sentences)\n",
        "input_vocab_size = len(en_tokenizer.word_index) + 1\n",
        "target_vocab_size = len(fr_tokenizer.word_index) + 1\n",
        "\n",
        "# Step 4: Define transformer model\n",
        "class Transformer(tf.keras.Model):\n",
        "    def __init__(self, input_vocab, target_vocab, d_model, num_heads, dff, pe_input, pe_target):\n",
        "        super().__init__()\n",
        "        self.encoder_embedding = tf.keras.layers.Embedding(input_vocab, d_model)\n",
        "        self.decoder_embedding = tf.keras.layers.Embedding(target_vocab, d_model)\n",
        "        self.pos_encoding_input = self.positional_encoding(pe_input, d_model)\n",
        "        self.pos_encoding_target = self.positional_encoding(pe_target, d_model)\n",
        "\n",
        "        self.enc_layer = tf.keras.layers.MultiHeadAttention(num_heads=num_heads, key_dim=d_model)\n",
        "        self.dec_layer = tf.keras.layers.MultiHeadAttention(num_heads=num_heads, key_dim=d_model)\n",
        "        self.dense_proj = tf.keras.Sequential([\n",
        "            tf.keras.layers.Dense(dff, activation='relu'),\n",
        "            tf.keras.layers.Dense(d_model)\n",
        "        ])\n",
        "        self.final_dense = tf.keras.layers.Dense(target_vocab)\n",
        "\n",
        "    def positional_encoding(self, max_len, dm):\n",
        "        pos = np.arange(max_len)[:, np.newaxis]\n",
        "        i = np.arange(dm)[np.newaxis, :]\n",
        "        angle_rates = 1 / np.power(10000, (2 * (i//2)) / np.float32(dm))\n",
        "        angle_rads = pos * angle_rates\n",
        "        angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
        "        angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
        "        return tf.cast(angle_rads, dtype=tf.float32)\n",
        "\n",
        "    def call(self, inputs, training=False):\n",
        "        inp, tar = inputs\n",
        "        enc = self.encoder_embedding(inp) + self.pos_encoding_input[:tf.shape(inp)[1]]\n",
        "        dec = self.decoder_embedding(tar) + self.pos_encoding_target[:tf.shape(tar)[1]]\n",
        "        enc_output = self.enc_layer(enc, enc)\n",
        "        dec_output = self.dec_layer(dec, enc_output)\n",
        "        final = self.dense_proj(dec_output)\n",
        "        return self.final_dense(final)\n",
        "\n",
        "# Step 5: Compile and train\n",
        "model = Transformer(input_vocab=input_vocab_size, target_vocab=target_vocab_size,\n",
        "                    d_model=64, num_heads=4, dff=128, pe_input=en_tensor.shape[1], pe_target=fr_tensor.shape[1])\n",
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "model.fit([en_tensor, fr_tensor[:, :-1]], fr_tensor[:, 1:], epochs=20, batch_size=32)\n",
        "\n",
        "# Step 6: Translation function\n",
        "def translate(sentence):\n",
        "    seq = en_tokenizer.texts_to_sequences([sentence])\n",
        "    padded = pad_sequences(seq, maxlen=en_tensor.shape[1], padding='post')\n",
        "    decoder_input = np.zeros((1, fr_tensor.shape[1]), dtype=np.int32)\n",
        "    decoder_input[0][0] = fr_tokenizer.word_index.get('<sos>', 1)\n",
        "\n",
        "    for i in range(1, fr_tensor.shape[1]):\n",
        "        output = model([padded, decoder_input[:, :-1]], training=False)\n",
        "        pred_id = tf.argmax(output[0, i-1]).numpy()\n",
        "        decoder_input[0][i] = pred_id\n",
        "        if pred_id == fr_tokenizer.word_index.get('<eos>'):\n",
        "            break\n",
        "\n",
        "    return ' '.join([fr_tokenizer.index_word.get(idx, '') for idx in decoder_input[0] if idx != 0])\n",
        "\n",
        "# Step 7: Evaluation\n",
        "results = []\n",
        "for i in range(10):\n",
        "    ref = [nltk.word_tokenize(french_sentences[i].replace('<sos>', '').replace('<eos>', '').strip())]\n",
        "    pred = nltk.word_tokenize(translate(english_sentences[i]))\n",
        "    bleu = sentence_bleu(ref, pred)\n",
        "    rouge = rouge_scorer.RougeScorer(['rouge1', 'rouge2'], use_stemmer=True).score(' '.join(ref[0]), ' '.join(pred))\n",
        "    results.append((english_sentences[i], french_sentences[i].replace('<sos>', '').replace('<eos>', '').strip(), ' '.join(pred), bleu, rouge['rouge1'].fmeasure, rouge['rouge2'].fmeasure))\n",
        "\n",
        "import pandas as pd\n",
        "pd.DataFrame(results, columns=[\"English\", \"French (Reference)\", \"Predicted French\", \"BLEU\", \"ROUGE-1\", \"ROUGE-2\"])"
      ],
      "metadata": {
        "id": "uslJwd2STlQW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Install and import libraries\n",
        "!pip install -q datasets nltk rouge-score\n",
        "\n",
        "from datasets import load_dataset\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import nltk\n",
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "from rouge_score import rouge_scorer\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Step 2: Prepare a small dataset (English-French)\n",
        "english_sentences = [\n",
        "    \"hello\", \"how are you\", \"i am fine\", \"what is your name\", \"nice to meet you\",\n",
        "    \"i love machine learning\", \"do you like pizza\", \"good morning\", \"thank you\", \"see you later\"\n",
        "]\n",
        "\n",
        "french_sentences = [\n",
        "    \"bonjour\", \"comment ça va\", \"je vais bien\", \"quel est ton nom\", \"ravi de vous rencontrer\",\n",
        "    \"j'aime l'apprentissage automatique\", \"aimes-tu la pizza\", \"bonjour\", \"merci\", \"à plus tard\"\n",
        "]\n",
        "\n",
        "# Step 3: Tokenization\n",
        "def tokenize(sentences, num_words=10000):\n",
        "    tokenizer = Tokenizer(num_words=num_words, oov_token='<OOV>')\n",
        "    tokenizer.fit_on_texts(sentences)\n",
        "    tensor = tokenizer.texts_to_sequences(sentences)\n",
        "    return tokenizer, pad_sequences(tensor, padding='post')\n",
        "\n",
        "en_tokenizer, en_tensor = tokenize(english_sentences)\n",
        "fr_tokenizer, fr_tensor = tokenize(french_sentences)\n",
        "input_vocab_size = len(en_tokenizer.word_index) + 1\n",
        "target_vocab_size = len(fr_tokenizer.word_index) + 1\n",
        "\n",
        "# Step 4: Define transformer model\n",
        "class Transformer(tf.keras.Model):\n",
        "    def __init__(self, input_vocab, target_vocab, d_model, num_heads, dff, pe_input, pe_target):\n",
        "        super().__init__()\n",
        "        self.encoder_embedding = tf.keras.layers.Embedding(input_vocab, d_model)\n",
        "        self.decoder_embedding = tf.keras.layers.Embedding(target_vocab, d_model)\n",
        "        self.pos_encoding_input = self.positional_encoding(pe_input, d_model)\n",
        "        self.pos_encoding_target = self.positional_encoding(pe_target, d_model)\n",
        "\n",
        "        self.enc_layer = tf.keras.layers.MultiHeadAttention(num_heads=num_heads, key_dim=d_model)\n",
        "        self.dec_layer = tf.keras.layers.MultiHeadAttention(num_heads=num_heads, key_dim=d_model)\n",
        "        self.dense_proj = tf.keras.Sequential([\n",
        "            tf.keras.layers.Dense(dff, activation='relu'),\n",
        "            tf.keras.layers.Dense(d_model)\n",
        "        ])\n",
        "        self.final_dense = tf.keras.layers.Dense(target_vocab)\n",
        "\n",
        "    def positional_encoding(self, max_len, dm):\n",
        "        pos = np.arange(max_len)[:, np.newaxis]\n",
        "        i = np.arange(dm)[np.newaxis, :]\n",
        "        angle_rates = 1 / np.power(10000, (2 * (i//2)) / np.float32(dm))\n",
        "        angle_rads = pos * angle_rates\n",
        "        angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
        "        angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
        "        return tf.cast(angle_rads, dtype=tf.float32)\n",
        "\n",
        "    def call(self, inputs, training=False):\n",
        "        inp, tar = inputs\n",
        "        enc = self.encoder_embedding(inp) + self.pos_encoding_input[:tf.shape(inp)[1]]\n",
        "        dec = self.decoder_embedding(tar) + self.pos_encoding_target[:tf.shape(tar)[1]]\n",
        "        enc_output = self.enc_layer(enc, enc)\n",
        "        dec_output = self.dec_layer(dec, enc_output)\n",
        "        final = self.dense_proj(dec_output)\n",
        "        return self.final_dense(final)\n",
        "\n",
        "# Step 5: Compile and train\n",
        "model = Transformer(input_vocab=input_vocab_size, target_vocab=target_vocab_size,\n",
        "                    d_model=64, num_heads=4, dff=128, pe_input=en_tensor.shape[1], pe_target=fr_tensor.shape[1])\n",
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "model.fit([en_tensor, fr_tensor[:, :-1]], fr_tensor[:, 1:], epochs=20, batch_size=32)\n",
        "\n",
        "# Step 6: Translation function\n",
        "def translate(sentence):\n",
        "    seq = en_tokenizer.texts_to_sequences([sentence])\n",
        "    padded = pad_sequences(seq, maxlen=en_tensor.shape[1], padding='post')\n",
        "    decoder_input = np.zeros((1, fr_tensor.shape[1]), dtype=np.int32)\n",
        "    decoder_input[0][0] = fr_tokenizer.word_index.get('<sos>', 1)\n",
        "\n",
        "    for i in range(1, fr_tensor.shape[1]):\n",
        "        output = model([padded, decoder_input[:, :-1]], training=False)\n",
        "        pred_id = tf.argmax(output[0, i-1]).numpy()\n",
        "        decoder_input[0][i] = pred_id\n",
        "        if pred_id == fr_tokenizer.word_index.get('<eos>'):\n",
        "            break\n",
        "\n",
        "    return ' '.join([fr_tokenizer.index_word.get(idx, '') for idx in decoder_input[0] if idx != 0])\n",
        "\n",
        "# Step 7: Evaluation\n",
        "results = []\n",
        "for i in range(10):\n",
        "    ref = [nltk.word_tokenize(french_sentences[i].replace('<sos>', '').replace('<eos>', '').strip())]\n",
        "    pred = nltk.word_tokenize(translate(english_sentences[i]))\n",
        "    bleu = sentence_bleu(ref, pred)\n",
        "    rouge = rouge_scorer.RougeScorer(['rouge1', 'rouge2'], use_stemmer=True).score(' '.join(ref[0]), ' '.join(pred))\n",
        "    results.append((english_sentences[i], french_sentences[i].replace('<sos>', '').replace('<eos>', '').strip(), ' '.join(pred), bleu, rouge['rouge1'].fmeasure, rouge['rouge2'].fmeasure))\n",
        "\n",
        "import pandas as pd\n",
        "pd.DataFrame(results, columns=[\"English\", \"French (Reference)\", \"Predicted French\", \"BLEU\", \"ROUGE-1\", \"ROUGE-2\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "iKKvCsKTYfZF",
        "outputId": "a545341d-1449-41c6-b656-1708ca62934f"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7s/step - accuracy: 0.0000e+00 - loss: 3.3420\n",
            "Epoch 2/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.4333 - loss: 3.2983\n",
            "Epoch 3/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.4333 - loss: 3.2217\n",
            "Epoch 4/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.4333 - loss: 3.1042\n",
            "Epoch 5/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.4333 - loss: 2.9288\n",
            "Epoch 6/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.4333 - loss: 2.7229\n",
            "Epoch 7/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.4333 - loss: 2.6827\n",
            "Epoch 8/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.4333 - loss: 2.7719\n",
            "Epoch 9/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.4333 - loss: 2.6436\n",
            "Epoch 10/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.4333 - loss: 2.5501\n",
            "Epoch 11/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.4333 - loss: 2.5548\n",
            "Epoch 12/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.4333 - loss: 2.5709\n",
            "Epoch 13/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.4333 - loss: 2.5556\n",
            "Epoch 14/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.4333 - loss: 2.5084\n",
            "Epoch 15/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.4333 - loss: 2.4537\n",
            "Epoch 16/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.4333 - loss: 2.4349\n",
            "Epoch 17/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.4333 - loss: 2.4476\n",
            "Epoch 18/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.4333 - loss: 2.4272\n",
            "Epoch 19/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.4333 - loss: 2.3822\n",
            "Epoch 20/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.4333 - loss: 2.3597\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                   English                  French (Reference)  \\\n",
              "0                    hello                             bonjour   \n",
              "1              how are you                       comment ça va   \n",
              "2                i am fine                        je vais bien   \n",
              "3        what is your name                    quel est ton nom   \n",
              "4         nice to meet you             ravi de vous rencontrer   \n",
              "5  i love machine learning  j'aime l'apprentissage automatique   \n",
              "6        do you like pizza                   aimes-tu la pizza   \n",
              "7             good morning                             bonjour   \n",
              "8                thank you                               merci   \n",
              "9            see you later                         à plus tard   \n",
              "\n",
              "  Predicted French  BLEU  ROUGE-1  ROUGE-2  \n",
              "0          < OOV >     0      0.0      0.0  \n",
              "1          < OOV >     0      0.0      0.0  \n",
              "2          < OOV >     0      0.0      0.0  \n",
              "3          < OOV >     0      0.0      0.0  \n",
              "4          < OOV >     0      0.0      0.0  \n",
              "5          < OOV >     0      0.0      0.0  \n",
              "6          < OOV >     0      0.0      0.0  \n",
              "7          < OOV >     0      0.0      0.0  \n",
              "8          < OOV >     0      0.0      0.0  \n",
              "9          < OOV >     0      0.0      0.0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-43250954-a51d-4a5f-a7b2-287e5a0cfff9\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>English</th>\n",
              "      <th>French (Reference)</th>\n",
              "      <th>Predicted French</th>\n",
              "      <th>BLEU</th>\n",
              "      <th>ROUGE-1</th>\n",
              "      <th>ROUGE-2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>hello</td>\n",
              "      <td>bonjour</td>\n",
              "      <td>&lt; OOV &gt;</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>how are you</td>\n",
              "      <td>comment ça va</td>\n",
              "      <td>&lt; OOV &gt;</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>i am fine</td>\n",
              "      <td>je vais bien</td>\n",
              "      <td>&lt; OOV &gt;</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>what is your name</td>\n",
              "      <td>quel est ton nom</td>\n",
              "      <td>&lt; OOV &gt;</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>nice to meet you</td>\n",
              "      <td>ravi de vous rencontrer</td>\n",
              "      <td>&lt; OOV &gt;</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>i love machine learning</td>\n",
              "      <td>j'aime l'apprentissage automatique</td>\n",
              "      <td>&lt; OOV &gt;</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>do you like pizza</td>\n",
              "      <td>aimes-tu la pizza</td>\n",
              "      <td>&lt; OOV &gt;</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>good morning</td>\n",
              "      <td>bonjour</td>\n",
              "      <td>&lt; OOV &gt;</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>thank you</td>\n",
              "      <td>merci</td>\n",
              "      <td>&lt; OOV &gt;</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>see you later</td>\n",
              "      <td>à plus tard</td>\n",
              "      <td>&lt; OOV &gt;</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-43250954-a51d-4a5f-a7b2-287e5a0cfff9')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-43250954-a51d-4a5f-a7b2-287e5a0cfff9 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-43250954-a51d-4a5f-a7b2-287e5a0cfff9');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-f7134e8d-63a4-4e66-851f-e4262a2414b9\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f7134e8d-63a4-4e66-851f-e4262a2414b9')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-f7134e8d-63a4-4e66-851f-e4262a2414b9 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"pd\",\n  \"rows\": 10,\n  \"fields\": [\n    {\n      \"column\": \"English\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"thank you\",\n          \"how are you\",\n          \"i love machine learning\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"French (Reference)\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 9,\n        \"samples\": [\n          \"merci\",\n          \"comment \\u00e7a va\",\n          \"j'aime l'apprentissage automatique\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Predicted French\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"< OOV >\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"BLEU\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ROUGE-1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 0.0,\n        \"max\": 0.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ROUGE-2\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 0.0,\n        \"max\": 0.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    }
  ]
}