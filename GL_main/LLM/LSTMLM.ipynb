{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from nltk.corpus import brown\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
        "from sklearn.model_selection import train_test_split\n",
        "import nltk\n",
        "nltk.download('brown')\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "id": "GzR7egrPy2Q5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Load and clean data\n",
        "sentences = brown.sents()\n",
        "sentences = [' '.join(sent).lower() for sent in sentences if len(sent) >= 3]\n",
        "sentences = sentences[:5000]  # Limit for quick training"
      ],
      "metadata": {
        "id": "4b59AF4Qy3wM"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Tokenize\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(sentences)\n",
        "word_index = tokenizer.word_index\n",
        "vocab_size = len(word_index) + 1"
      ],
      "metadata": {
        "id": "yaDwuQHMy4yW"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: Create training samples (trigrams: context → next word)\n",
        "X, y = [], []\n",
        "for sent in sentences:\n",
        "    tokens = tokenizer.texts_to_sequences([sent])[0]\n",
        "    for i in range(2, len(tokens)):\n",
        "        context = tokens[i-2:i]\n",
        "        target = tokens[i]\n",
        "        X.append(context)\n",
        "        y.append(target)\n",
        "\n",
        "X = np.array(X)\n",
        "y = np.array(y)"
      ],
      "metadata": {
        "id": "sZg9HuDvy79a"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4: Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "iJWZkTv1y-93"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 5: Model\n",
        "embedding_dim = 100\n",
        "lstm_units = 128\n",
        "\n",
        "model = Sequential()\n",
        "# Changed here: input_shape instead of input_length\n",
        "model.add(Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_shape=(2,)))\n",
        "model.add(LSTM(lstm_units))\n",
        "model.add(Dense(vocab_size, activation='softmax'))\n",
        "\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "LFXzSm7azBOq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 6: Train\n",
        "model.fit(X_train, y_train, epochs=5, batch_size=256, validation_data=(X_test, y_test))"
      ],
      "metadata": {
        "id": "QzRbDbuAzCxG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Step 7: Evaluation on Test Set\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "# Optional: Top-3 Accuracy\n",
        "def top_k_accuracy(model, X, y_true, k=3):\n",
        "    preds = model.predict(X, verbose=0)\n",
        "    top_k_preds = np.argsort(preds, axis=1)[:, -k:]\n",
        "    match = np.any(top_k_preds == y_true.reshape(-1, 1), axis=1)\n",
        "    return np.mean(match)\n",
        "\n",
        "top3 = top_k_accuracy(model, X_test, y_test, k=3)\n",
        "print(f\"Top-3 Accuracy: {top3:.4f}\")"
      ],
      "metadata": {
        "id": "-tzBWSrbzFLd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P-pNPXIGv3dy"
      },
      "outputs": [],
      "source": [
        "# Step 8: Sample Predictions\n",
        "reverse_word_index = {v: k for k, v in word_index.items()}\n",
        "\n",
        "print(\"Sample Predictions:\")\n",
        "for i in range(5):\n",
        "    context = X_test[i]\n",
        "    true_word = reverse_word_index.get(y_test[i], \"<UNK>\")\n",
        "    pred = model.predict(np.array([context]), verbose=0)\n",
        "    pred_word = reverse_word_index.get(np.argmax(pred), \"<UNK>\")\n",
        "    print(f\"Context: '{reverse_word_index[context[0]]} {reverse_word_index[context[1]]}' → Prediction: '{pred_word}' | Actual: '{true_word}'\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "context = 'i am'\n",
        "# Tokenize the context words\n",
        "context_sequence = tokenizer.texts_to_sequences([context.split()])[0]\n",
        "\n",
        "# Ensure the context has two words, padding or truncating if necessary\n",
        "if len(context_sequence) > 2:\n",
        "    context_sequence = context_sequence[-2:]\n",
        "elif len(context_sequence) < 2:\n",
        "    # Handle cases where the context has fewer than two words\n",
        "    print(\"Error: Context must contain at least two words.\")\n",
        "    pred_word = \"<Error>\"\n",
        "else:\n",
        "    # Reshape for the model\n",
        "    context_sequence = np.array([context_sequence])\n",
        "\n",
        "    # Predict the next word probabilities\n",
        "    pred = model.predict(context_sequence, verbose=0)[0]\n",
        "\n",
        "    # Get the index of the word with the highest probability\n",
        "    predicted_word_index = np.argmax(pred)\n",
        "\n",
        "    # Get the predicted word from the reverse word index\n",
        "    pred_word = reverse_word_index.get(predicted_word_index, \"<UNK>\")\n",
        "\n",
        "print (pred_word)"
      ],
      "metadata": {
        "id": "X9S3awt2zdgL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}