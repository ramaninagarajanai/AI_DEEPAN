{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from nltk.corpus import brown\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, SimpleRNN, Dense\n",
        "from sklearn.model_selection import train_test_split\n",
        "import nltk\n",
        "nltk.download('brown')\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "id": "GzR7egrPy2Q5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3fdeaf8-5492-467d-c41b-3546daa5ab68"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/brown.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Load and clean data\n",
        "sentences = brown.sents()\n",
        "sentences = [' '.join(sent).lower() for sent in sentences if len(sent) >= 3]\n",
        "sentences = sentences[:5000]  # Limit for quick training"
      ],
      "metadata": {
        "id": "4b59AF4Qy3wM"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Tokenize\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(sentences)\n",
        "word_index = tokenizer.word_index\n",
        "vocab_size = len(word_index) + 1"
      ],
      "metadata": {
        "id": "yaDwuQHMy4yW"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: Create training samples (trigrams: context → next word)\n",
        "X, y = [], []\n",
        "for sent in sentences:\n",
        "    tokens = tokenizer.texts_to_sequences([sent])[0]\n",
        "    for i in range(2, len(tokens)):\n",
        "        context = tokens[i-2:i]\n",
        "        target = tokens[i]\n",
        "        X.append(context)\n",
        "        y.append(target)\n",
        "\n",
        "X = np.array(X)\n",
        "y = np.array(y)"
      ],
      "metadata": {
        "id": "sZg9HuDvy79a"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4: Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "iJWZkTv1y-93"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 5: Model\n",
        "embedding_dim = 100\n",
        "rnn_units = 128\n",
        "\n",
        "model = Sequential()\n",
        "# Changed here: input_shape instead of input_length\n",
        "model.add(Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_shape=(2,)))\n",
        "model.add(SimpleRNN(rnn_units))\n",
        "model.add(Dense(vocab_size, activation='softmax'))\n",
        "\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "LFXzSm7azBOq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "outputId": "1091471c-99f0-44af-da02-bf3a83deecea"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m100\u001b[0m)         │     \u001b[38;5;34m1,303,200\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ simple_rnn (\u001b[38;5;33mSimpleRNN\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m29,312\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13032\u001b[0m)          │     \u001b[38;5;34m1,681,128\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)         │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,303,200</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ simple_rnn (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SimpleRNN</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">29,312</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13032</span>)          │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,681,128</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,013,640\u001b[0m (11.50 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,013,640</span> (11.50 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,013,640\u001b[0m (11.50 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,013,640</span> (11.50 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 6: Train\n",
        "model.fit(X_train, y_train, epochs=5, batch_size=256, validation_data=(X_test, y_test))"
      ],
      "metadata": {
        "id": "QzRbDbuAzCxG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "106305c0-f11a-4a6d-82b7-146dc54cd5d2"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 160ms/step - accuracy: 0.0623 - loss: 8.2834 - val_accuracy: 0.0789 - val_loss: 7.2762\n",
            "Epoch 2/5\n",
            "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 149ms/step - accuracy: 0.0874 - loss: 6.9165 - val_accuracy: 0.0942 - val_loss: 7.1359\n",
            "Epoch 3/5\n",
            "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 150ms/step - accuracy: 0.1071 - loss: 6.5347 - val_accuracy: 0.1055 - val_loss: 7.1107\n",
            "Epoch 4/5\n",
            "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 149ms/step - accuracy: 0.1213 - loss: 6.2280 - val_accuracy: 0.1078 - val_loss: 7.1452\n",
            "Epoch 5/5\n",
            "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 145ms/step - accuracy: 0.1305 - loss: 5.9682 - val_accuracy: 0.1088 - val_loss: 7.2201\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x787a1e5ffa50>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Step 7: Evaluation on Test Set\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "# Optional: Top-3 Accuracy\n",
        "def top_k_accuracy(model, X, y_true, k=3):\n",
        "    preds = model.predict(X, verbose=0)\n",
        "    top_k_preds = np.argsort(preds, axis=1)[:, -k:]\n",
        "    match = np.any(top_k_preds == y_true.reshape(-1, 1), axis=1)\n",
        "    return np.mean(match)\n",
        "\n",
        "top3 = top_k_accuracy(model, X_test, y_test, k=3)\n",
        "print(f\"Top-3 Accuracy: {top3:.4f}\")"
      ],
      "metadata": {
        "id": "-tzBWSrbzFLd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e246379-15d6-4e60-85e4-8fe44626a48e"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m568/568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 12ms/step - accuracy: 0.1124 - loss: 7.2202\n",
            "Test Accuracy: 0.1088\n",
            "Top-3 Accuracy: 0.1805\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "P-pNPXIGv3dy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "02c0694d-e6f1-4486-cba7-d6d4a53a570a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample Predictions:\n",
            "Context: 'catholic atmosphere' → Prediction: 'of' | Actual: 'is'\n",
            "Context: 'any test' → Prediction: 'the' | Actual: 'of'\n",
            "Context: 'that an' → Prediction: 'own' | Actual: 'increase'\n",
            "Context: 'city's snow' → Prediction: 'in' | Actual: 'clearing'\n",
            "Context: 'interstate commerce' → Prediction: 'and' | Actual: 'commission'\n"
          ]
        }
      ],
      "source": [
        "# Step 8: Sample Predictions\n",
        "reverse_word_index = {v: k for k, v in word_index.items()}\n",
        "\n",
        "print(\"Sample Predictions:\")\n",
        "for i in range(5):\n",
        "    context = X_test[i]\n",
        "    true_word = reverse_word_index.get(y_test[i], \"<UNK>\")\n",
        "    pred = model.predict(np.array([context]), verbose=0)\n",
        "    pred_word = reverse_word_index.get(np.argmax(pred), \"<UNK>\")\n",
        "    print(f\"Context: '{reverse_word_index[context[0]]} {reverse_word_index[context[1]]}' → Prediction: '{pred_word}' | Actual: '{true_word}'\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "context = 'i am'\n",
        "# Tokenize the context words\n",
        "context_sequence = tokenizer.texts_to_sequences([context.split()])[0]\n",
        "\n",
        "# Ensure the context has two words, padding or truncating if necessary\n",
        "if len(context_sequence) > 2:\n",
        "    context_sequence = context_sequence[-2:]\n",
        "elif len(context_sequence) < 2:\n",
        "    # Handle cases where the context has fewer than two words\n",
        "    print(\"Error: Context must contain at least two words.\")\n",
        "    pred_word = \"<Error>\"\n",
        "else:\n",
        "    # Reshape for the model\n",
        "    context_sequence = np.array([context_sequence])\n",
        "\n",
        "    # Predict the next word probabilities\n",
        "    pred = model.predict(context_sequence, verbose=0)[0]\n",
        "\n",
        "    # Get the index of the word with the highest probability\n",
        "    predicted_word_index = np.argmax(pred)\n",
        "\n",
        "    # Get the predicted word from the reverse word index\n",
        "    pred_word = reverse_word_index.get(predicted_word_index, \"<UNK>\")\n",
        "\n",
        "print (pred_word)"
      ],
      "metadata": {
        "id": "X9S3awt2zdgL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b82541f-36fe-4ab3-d9fa-53029c3d7cfc"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "a\n"
          ]
        }
      ]
    }
  ]
}