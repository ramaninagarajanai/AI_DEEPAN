{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import BertTokenizer, BertModel\n",
        "from sklearn.metrics.pairwise import cosine_similarity"
      ],
      "metadata": {
        "id": "2RClYLmXQV_v"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# --- Step 1: Load Pre-trained BERT Model and Tokenizer ---\n",
        "print(\"Loading BERT model and tokenizer...\")\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "model = BertModel.from_pretrained('bert-base-uncased')\n",
        "print(\"BERT model loaded successfully! âœ…\")"
      ],
      "metadata": {
        "id": "_3R1V8hzQZPj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Step 2: Define the same sentences as before ---\n",
        "sentences = [\n",
        "    \"I went to the river bank to fish.\",\n",
        "    \"I need to go to the bank to withdraw money.\"\n",
        "]"
      ],
      "metadata": {
        "id": "-YI1SFM4QaN0"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Step 3: Tokenize the sentences and get BERT embeddings ---\n",
        "# The tokenizer will add special tokens ([CLS], [SEP]) and convert tokens to IDs.\n",
        "# `padding=True` makes sure both sentences have the same length.\n",
        "# `truncation=True` ensures they don't exceed the model's max length.\n",
        "# `return_tensors='pt'` returns PyTorch tensors.\n",
        "inputs = tokenizer(sentences, return_tensors='pt', padding=True, truncation=True)\n",
        "\n",
        "\n",
        "with torch.no_grad():\n",
        "    outputs = model(**inputs)\n",
        "\n",
        "# The embeddings are in `last_hidden_state`.\n",
        "\n",
        "last_hidden_states = outputs.last_hidden_state"
      ],
      "metadata": {
        "id": "HHss0KZgQlXR"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Step 4: Extract the vector for the word \"bank\" from each sentence ---\n",
        "\n",
        "\n",
        "# For sentence 1\n",
        "\n",
        "tokens_1 = tokenizer.convert_ids_to_tokens(inputs['input_ids'][0])\n",
        "bank_index_1 = tokens_1.index('bank')\n",
        "bank_vec_1 = last_hidden_states[0, bank_index_1, :]\n",
        "print(f\"\\nSentence 1 Tokens: {tokens_1}\")\n",
        "print(f\"Index of 'bank' in Sentence 1: {bank_index_1}\")\n",
        "\n",
        "\n",
        "# For sentence 2\n",
        "tokens_2 = tokenizer.convert_ids_to_tokens(inputs['input_ids'][1])\n",
        "bank_index_2 = tokens_2.index('bank')\n",
        "bank_vec_2 = last_hidden_states[1, bank_index_2, :]\n",
        "print(f\"Sentence 2 Tokens: {tokens_2}\")\n",
        "print(f\"Index of 'bank' in Sentence 2: {bank_index_2}\")\n",
        "\n",
        "\n",
        "# \"river\" from sentence 1\n",
        "river_index = tokens_1.index('river')\n",
        "river_vec = last_hidden_states[0, river_index, :]\n"
      ],
      "metadata": {
        "id": "_baQ8bdJQ1To"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Step 5: Compare the vectors using Cosine Similarity ---\n",
        "\n",
        "bank_vec_1_reshaped = bank_vec_1.numpy().reshape(1, -1)\n",
        "bank_vec_2_reshaped = bank_vec_2.numpy().reshape(1, -1)\n",
        "river_vec_reshaped = river_vec.numpy().reshape(1, -1)\n",
        "\n",
        "# Compare the two \"bank\" vectors\n",
        "similarity_banks = cosine_similarity(bank_vec_1_reshaped, bank_vec_2_reshaped)[0][0]\n",
        "\n",
        "# Compare \"bank\" (from sentence 1) with \"river\"\n",
        "similarity_bank_river = cosine_similarity(bank_vec_1_reshaped, river_vec_reshaped)[0][0]"
      ],
      "metadata": {
        "id": "-GzoRr82Q94u"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7KHe8u0_QTBG"
      },
      "outputs": [],
      "source": [
        "# --- Step 6: Print the results ---\n",
        "print(\"\\n--- Cosine Similarity Results ---\")\n",
        "print(f\"Similarity between 'bank' (river context) and 'bank' (money context): {similarity_banks:.4f}\")\n",
        "print(f\"Similarity between 'bank' (river context) and 'river': {similarity_bank_river:.4f}\")"
      ]
    }
  ]
}